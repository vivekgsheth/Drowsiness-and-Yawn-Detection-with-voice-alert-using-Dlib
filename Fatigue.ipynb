{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fatigue.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekgsheth/Drowsiness-and-Yawn-Detection-with-voice-alert-using-Dlib/blob/master/Fatigue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcDceJ9QuVxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a54bc795-cd87-49f3-94f3-c142e1bea77b"
      },
      "source": [
        "!unzip diFatigue-dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  diFatigue-dataset.zip\n",
            "replace diFatigue-dataset/Fatigue/LeftEye/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpISb-n81ClQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b7f8804-d40b-4bcd-88f1-5044e6b4027d"
      },
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "fat_right_eye=[]\n",
        "fat_left_eye=[]\n",
        "fat_mouth=[]\n",
        "fat=[]\n",
        "non_fat_right_eye=[]\n",
        "non_fat_left_eye=[]\n",
        "non_fat_mouth=[]\n",
        "non_fat=[]\n",
        "\n",
        "# im = Image.open(BytesIO(uploaded['Image_file_name.jpg']))\n",
        "items = os.listdir('/content/diFatigue-dataset/Fatigue/RightEye')\n",
        "for item in items:\n",
        "  if item == \".DS_Store\":\n",
        "    continue\n",
        "  im = Image.open('/content/diFatigue-dataset/Fatigue/RightEye/'+item)\n",
        "  pix_val = list(im.getdata())\n",
        "  fat_right_eye.append(pix_val)\n",
        "  fat.append(pix_val)\n",
        "\n",
        "items = os.listdir('/content/diFatigue-dataset/Fatigue/LeftEye')\n",
        "for item in items:\n",
        "  if item == \".DS_Store\":\n",
        "    continue\n",
        "  im = Image.open('/content/diFatigue-dataset/Fatigue/LeftEye/'+item)\n",
        "  pix_val = list(im.getdata())\n",
        "  fat_left_eye.append(pix_val)\n",
        "  fat.append(pix_val)\n",
        "\n",
        "items = os.listdir('/content/diFatigue-dataset/Fatigue/Mouth')\n",
        "for item in items:\n",
        "  if item == \".DS_Store\":\n",
        "    continue\n",
        "  im = Image.open('/content/diFatigue-dataset/Fatigue/Mouth/'+item)\n",
        "  pix_val = list(im.getdata())[0:2048]\n",
        "  fat_mouth.append(pix_val)\n",
        "  fat.append(pix_val)\n",
        "\n",
        "items = os.listdir('/content/diFatigue-dataset/Non-Fatigue/LeftEye')\n",
        "for item in items:\n",
        "  if item == \".DS_Store\":\n",
        "    continue\n",
        "  im = Image.open('/content/diFatigue-dataset/Non-Fatigue/LeftEye/'+item)\n",
        "  pix_val = list(im.getdata())\n",
        "  non_fat_left_eye.append(pix_val)\n",
        "  non_fat.append(pix_val)\n",
        "    \n",
        "\n",
        "items = os.listdir('/content/diFatigue-dataset/Non-Fatigue/RightEye')\n",
        "for item in items:\n",
        "  if item == \".DS_Store\":\n",
        "    continue\n",
        "  im = Image.open('/content/diFatigue-dataset/Non-Fatigue/RightEye/'+item)\n",
        "  pix_val = list(im.getdata())\n",
        "  non_fat_right_eye.append(pix_val)\n",
        "  non_fat.append(pix_val)\n",
        "\n",
        "items = os.listdir('/content/diFatigue-dataset/Non-Fatigue/Mouth')\n",
        "for item in items:\n",
        "  if item == \".DS_Store\":\n",
        "    continue\n",
        "  im = Image.open('/content/diFatigue-dataset/Non-Fatigue/Mouth/'+item)\n",
        "  pix_val = list(im.getdata())[0:2048]\n",
        "  print(len(pix_val))\n",
        "  non_fat_mouth.append(pix_val)\n",
        "  non_fat.append(pix_val)\n",
        "\n",
        "print(non_fat_mouth[0:2])\n",
        "\n",
        "\n",
        "# print(items)\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "[[100, 102, 102, 100, 100, 101, 100, 98, 101, 103, 106, 106, 106, 106, 107, 109, 110, 111, 114, 118, 119, 119, 124, 129, 129, 127, 124, 122, 121, 120, 122, 124, 133, 134, 139, 144, 148, 150, 149, 145, 145, 146, 147, 148, 149, 147, 145, 143, 138, 134, 129, 127, 128, 131, 131, 129, 130, 132, 128, 125, 125, 127, 131, 130, 101, 102, 102, 101, 100, 101, 102, 101, 102, 105, 108, 109, 109, 109, 110, 112, 112, 113, 116, 120, 121, 122, 126, 130, 129, 127, 124, 123, 122, 121, 123, 125, 133, 131, 134, 140, 145, 148, 148, 146, 145, 145, 146, 147, 147, 146, 144, 142, 138, 134, 129, 126, 126, 128, 128, 128, 130, 132, 127, 125, 125, 128, 132, 130, 101, 103, 103, 101, 99, 101, 103, 104, 103, 106, 109, 110, 110, 110, 111, 113, 114, 114, 117, 121, 123, 124, 127, 130, 130, 127, 124, 124, 123, 121, 123, 126, 126, 122, 126, 136, 143, 146, 147, 146, 147, 147, 148, 148, 148, 146, 143, 140, 138, 135, 130, 126, 126, 127, 128, 127, 130, 130, 125, 123, 125, 128, 131, 129, 101, 102, 103, 100, 99, 99, 102, 103, 105, 107, 108, 109, 109, 109, 112, 114, 115, 115, 117, 120, 123, 125, 127, 129, 129, 125, 124, 124, 123, 121, 122, 126, 122, 117, 121, 134, 142, 145, 146, 147, 150, 149, 149, 149, 149, 146, 142, 139, 137, 134, 129, 127, 127, 129, 128, 127, 128, 127, 123, 122, 124, 126, 129, 126, 102, 103, 103, 101, 99, 99, 101, 103, 106, 108, 109, 108, 108, 110, 113, 115, 115, 115, 116, 119, 122, 124, 126, 128, 125, 123, 122, 124, 123, 122, 123, 126, 123, 117, 120, 132, 140, 142, 144, 147, 151, 151, 150, 150, 149, 145, 141, 137, 135, 132, 129, 127, 129, 130, 129, 126, 126, 126, 122, 122, 123, 125, 126, 123, 103, 103, 103, 103, 101, 100, 102, 103, 106, 107, 108, 109, 109, 110, 113, 116, 116, 116, 117, 118, 120, 123, 125, 126, 122, 122, 123, 125, 125, 124, 125, 127, 124, 120, 125, 139, 146, 147, 148, 150, 153, 152, 151, 150, 149, 146, 142, 138, 136, 133, 130, 129, 130, 130, 128, 125, 125, 124, 120, 120, 121, 121, 123, 120, 102, 101, 101, 101, 101, 101, 102, 103, 104, 106, 109, 110, 110, 110, 113, 114, 115, 116, 117, 117, 117, 119, 120, 121, 120, 122, 123, 124, 125, 125, 126, 125, 124, 121, 127, 139, 145, 146, 147, 150, 152, 150, 148, 147, 147, 145, 142, 139, 136, 135, 132, 130, 130, 129, 127, 125, 123, 123, 119, 118, 117, 117, 119, 118, 100, 99, 98, 99, 100, 101, 102, 103, 104, 107, 110, 112, 111, 111, 112, 113, 113, 115, 116, 115, 114, 115, 116, 117, 117, 120, 122, 122, 123, 124, 123, 121, 121, 115, 116, 123, 127, 130, 135, 140, 147, 145, 142, 141, 141, 141, 139, 137, 136, 135, 133, 130, 128, 127, 126, 125, 124, 123, 119, 117, 116, 115, 118, 118, 97, 96, 97, 98, 99, 98, 99, 101, 103, 107, 111, 113, 112, 110, 110, 110, 108, 109, 110, 110, 107, 107, 108, 107, 112, 118, 122, 120, 116, 115, 112, 108, 107, 103, 101, 102, 104, 107, 113, 120, 126, 125, 128, 129, 128, 129, 131, 131, 132, 132, 130, 126, 124, 124, 124, 124, 122, 120, 118, 116, 115, 114, 114, 115, 97, 96, 96, 98, 99, 99, 98, 98, 103, 107, 111, 112, 110, 107, 105, 104, 102, 102, 103, 102, 99, 98, 99, 97, 102, 109, 114, 112, 107, 104, 100, 97, 94, 92, 90, 92, 94, 96, 100, 104, 107, 108, 112, 114, 114, 115, 119, 120, 124, 124, 123, 122, 121, 122, 123, 122, 121, 119, 117, 116, 116, 115, 114, 114, 96, 95, 95, 97, 99, 98, 97, 96, 102, 105, 109, 109, 105, 101, 98, 97, 95, 94, 94, 92, 90, 90, 91, 89, 93, 99, 104, 102, 97, 93, 90, 87, 89, 88, 88, 90, 92, 93, 93, 94, 93, 94, 97, 99, 98, 101, 105, 108, 111, 112, 113, 114, 116, 119, 120, 119, 117, 115, 113, 114, 113, 111, 109, 108, 94, 93, 93, 95, 97, 98, 97, 96, 100, 101, 102, 101, 98, 94, 91, 90, 89, 87, 86, 85, 84, 86, 88, 87, 88, 92, 95, 94, 91, 88, 87, 86, 83, 83, 84, 85, 88, 88, 87, 84, 91, 89, 89, 89, 87, 90, 94, 97, 98, 100, 102, 104, 107, 110, 113, 114, 114, 112, 112, 113, 111, 107, 104, 103, 92, 92, 92, 93, 96, 97, 98, 97, 98, 97, 94, 92, 90, 88, 86, 85, 84, 82, 81, 80, 80, 84, 86, 86, 85, 87, 89, 89, 88, 87, 86, 86, 83, 83, 84, 86, 89, 89, 87, 85, 88, 85, 84, 83, 82, 82, 84, 84, 88, 90, 92, 93, 95, 98, 103, 106, 107, 107, 108, 110, 107, 101, 97, 97, 90, 90, 90, 92, 95, 97, 97, 95, 94, 91, 88, 86, 85, 84, 83, 82, 81, 79, 79, 79, 79, 82, 84, 84, 82, 83, 85, 88, 88, 86, 84, 84, 81, 81, 82, 84, 85, 84, 83, 82, 84, 82, 81, 82, 81, 81, 80, 78, 83, 84, 85, 85, 86, 88, 92, 96, 98, 99, 102, 104, 102, 96, 92, 93, 88, 87, 87, 90, 94, 96, 93, 89, 85, 84, 83, 82, 81, 81, 80, 80, 80, 79, 80, 80, 79, 81, 82, 80, 79, 80, 83, 86, 86, 84, 82, 82, 81, 79, 80, 81, 81, 79, 79, 80, 80, 79, 80, 81, 81, 80, 79, 77, 79, 79, 80, 80, 79, 79, 82, 85, 87, 88, 92, 97, 96, 91, 88, 88, 86, 85, 85, 88, 93, 94, 89, 83, 78, 79, 80, 80, 80, 79, 79, 79, 79, 79, 80, 81, 79, 80, 80, 78, 76, 77, 81, 84, 83, 80, 80, 81, 79, 78, 78, 79, 78, 75, 75, 77, 77, 75, 77, 78, 77, 77, 78, 77, 76, 75, 75, 76, 75, 74, 74, 76, 75, 75, 79, 85, 85, 81, 78, 78, 84, 85, 85, 87, 90, 88, 82, 79, 75, 76, 77, 77, 78, 79, 79, 78, 77, 77, 77, 77, 78, 78, 77, 75, 76, 76, 79, 81, 79, 78, 79, 78, 80, 78, 74, 76, 71, 69, 69, 69, 69, 68, 73, 74, 73, 75, 74, 75, 74, 75, 74, 73, 72, 73, 72, 70, 70, 71, 72, 72, 72, 71, 69, 68, 83, 83, 82, 83, 83, 78, 74, 74, 74, 74, 74, 74, 75, 75, 75, 74, 74, 73, 72, 74, 76, 76, 74, 73, 74, 74, 76, 78, 78, 77, 76, 75, 77, 78, 74, 70, 67, 67, 68, 67, 65, 67, 68, 69, 68, 70, 75, 75, 75, 75, 74, 73, 73, 74, 73, 71, 70, 72, 73, 73, 73, 74, 73, 72, 82, 81, 80, 80, 77, 70, 67, 71, 74, 73, 73, 73, 74, 74, 73, 72, 70, 67, 67, 70, 73, 73, 72, 72, 73, 72, 72, 74, 75, 74, 72, 70, 70, 73, 72, 68, 71, 74, 73, 73, 68, 72, 71, 72, 72, 74, 84, 83, 81, 82, 81, 80, 80, 82, 81, 78, 78, 81, 83, 83, 84, 87, 89, 88, 79, 79, 78, 76, 73, 68, 67, 71, 71, 70, 70, 71, 70, 69, 67, 66, 65, 63, 64, 67, 70, 70, 71, 71, 72, 71, 69, 69, 71, 71, 70, 70, 76, 79, 82, 82, 90, 91, 87, 90, 87, 88, 87, 87, 89, 94, 99, 97, 91, 93, 94, 92, 92, 93, 93, 92, 93, 96, 97, 97, 99, 105, 109, 109, 77, 79, 76, 72, 69, 68, 67, 68, 70, 69, 68, 67, 65, 62, 60, 59, 60, 59, 61, 64, 66, 67, 68, 70, 69, 70, 68, 69, 73, 75, 78, 82, 92, 97, 99, 101, 105, 104, 103, 111, 113, 107, 109, 105, 108, 115, 109, 105, 101, 105, 106, 103, 101, 102, 104, 104, 105, 107, 107, 106, 109, 115, 120, 122, 77, 78, 73, 67, 66, 66, 65, 64, 67, 66, 65, 63, 60, 57, 56, 57, 59, 60, 63, 66, 68, 70, 72, 73, 73, 75, 75, 76, 83, 87, 93, 100, 107, 115, 114, 118, 115, 117, 123, 133, 131, 121, 123, 117, 118, 124, 112, 107, 108, 113, 115, 110, 106, 107, 110, 111, 112, 112, 112, 112, 115, 119, 124, 126, 76, 74, 68, 62, 61, 61, 61, 62, 62, 60, 59, 58, 57, 57, 62, 66, 70, 74, 77, 80, 84, 88, 88, 87, 89, 92, 90, 91, 98, 102, 106, 114, 120, 134, 127, 132, 127, 136, 143, 141, 132, 123, 123, 118, 118, 122, 113, 110, 115, 120, 120, 113, 109, 110, 112, 113, 116, 115, 116, 119, 122, 124, 126, 128, 74, 70, 63, 58, 58, 57, 58, 61, 60, 59, 59, 60, 62, 66, 75, 83, 86, 90, 95, 98, 103, 107, 107, 104, 105, 108, 105, 105, 110, 112, 113, 120, 130, 146, 134, 138, 133, 147, 146, 129, 126, 119, 116, 114, 114, 117, 115, 113, 119, 123, 122, 115, 110, 111, 113, 112, 118, 116, 118, 124, 127, 128, 129, 130, 67, 61, 57, 56, 55, 56, 59, 60, 60, 60, 63, 70, 77, 83, 89, 94, 97, 103, 106, 111, 115, 122, 120, 116, 117, 121, 115, 110, 113, 114, 115, 122, 136, 145, 130, 135, 140, 146, 130, 112, 115, 113, 111, 109, 111, 116, 119, 117, 121, 121, 118, 111, 109, 112, 112, 115, 119, 118, 121, 126, 128, 128, 131, 133, 63, 61, 59, 58, 58, 59, 60, 63, 65, 67, 72, 80, 87, 92, 96, 99, 102, 107, 109, 114, 118, 125, 123, 120, 120, 125, 120, 113, 111, 111, 115, 126, 136, 140, 125, 128, 130, 127, 115, 107, 109, 109, 109, 110, 112, 118, 120, 117, 117, 117, 116, 111, 111, 113, 113, 117, 119, 118, 122, 127, 128, 129, 131, 134, 62, 64, 62, 62, 64, 63, 64, 68, 71, 74, 80, 85, 90, 94, 97, 99, 103, 108, 109, 114, 117, 124, 122, 119, 120, 125, 121, 113, 110, 108, 112, 122, 127, 133, 122, 120, 121, 112, 105, 106, 105, 105, 108, 110, 112, 117, 118, 115, 115, 114, 115, 113, 113, 114, 114, 118, 120, 120, 124, 128, 129, 129, 132, 134, 66, 69, 67, 65, 69, 68, 68, 73, 75, 78, 82, 84, 86, 90, 94, 96, 100, 104, 105, 111, 113, 118, 116, 113, 115, 118, 115, 110, 110, 108, 107, 112, 114, 126, 121, 111, 113, 106, 103, 104, 105, 106, 109, 109, 109, 112, 114, 112, 116, 114, 115, 114, 115, 114, 112, 117, 120, 120, 124, 128, 129, 130, 132, 133, 73, 74, 70, 68, 72, 73, 72, 76, 77, 80, 83, 83, 84, 87, 91, 94, 95, 98, 100, 107, 109, 113, 110, 109, 109, 111, 110, 108, 108, 106, 104, 105, 106, 117, 116, 105, 107, 102, 102, 103, 108, 109, 110, 108, 106, 108, 111, 111, 116, 115, 115, 115, 115, 114, 112, 118, 122, 121, 124, 128, 130, 131, 132, 131, 78, 78, 74, 72, 75, 77, 77, 78, 79, 82, 84, 85, 84, 84, 85, 87, 88, 90, 93, 100, 104, 108, 106, 105, 105, 108, 108, 105, 104, 102, 103, 105, 105, 109, 110, 103, 105, 101, 103, 107, 109, 109, 109, 107, 105, 106, 111, 113, 113, 113, 114, 114, 115, 115, 114, 120, 124, 123, 126, 129, 131, 132, 133, 132, 82, 81, 80, 78, 79, 81, 80, 79, 79, 81, 85, 86, 85, 82, 81, 83, 85, 86, 86, 94, 97, 102, 102, 103, 102, 105, 105, 103, 101, 101, 103, 105, 108, 106, 107, 105, 106, 104, 106, 109, 107, 106, 106, 105, 105, 107, 111, 112, 109, 110, 113, 113, 114, 115, 116, 122, 124, 124, 127, 130, 130, 131, 133, 133, 85, 84, 85, 84, 83, 83, 82, 78, 79, 80, 84, 88, 87, 84, 85, 87, 86, 85, 84, 91, 94, 99, 100, 103, 101, 102, 103, 102, 102, 103, 104, 105, 109, 107, 108, 106, 104, 105, 105, 105, 105, 103, 103, 104, 105, 107, 109, 109, 107, 109, 113, 112, 113, 115, 117, 123, 122, 123, 127, 128, 127, 128, 130, 131], [108, 107, 108, 108, 108, 107, 103, 101, 102, 102, 103, 103, 104, 104, 104, 105, 105, 105, 106, 107, 109, 111, 115, 117, 116, 116, 117, 118, 117, 115, 115, 115, 118, 122, 126, 127, 129, 132, 132, 131, 131, 132, 133, 135, 137, 141, 145, 147, 151, 153, 153, 152, 150, 149, 149, 149, 148, 145, 143, 142, 139, 137, 137, 135, 105, 105, 105, 106, 106, 105, 103, 102, 103, 103, 104, 104, 105, 105, 105, 105, 105, 106, 106, 107, 109, 113, 116, 119, 118, 118, 119, 119, 117, 115, 114, 114, 117, 121, 124, 127, 129, 132, 134, 133, 133, 133, 134, 136, 138, 142, 146, 149, 150, 151, 152, 151, 149, 148, 147, 147, 145, 143, 142, 141, 138, 136, 135, 133, 102, 102, 103, 104, 104, 104, 103, 103, 104, 104, 105, 106, 106, 106, 106, 106, 106, 106, 106, 107, 110, 114, 118, 119, 120, 120, 120, 120, 117, 115, 113, 114, 116, 119, 123, 126, 129, 133, 135, 134, 134, 135, 135, 137, 140, 143, 147, 149, 150, 151, 151, 150, 149, 147, 146, 145, 143, 141, 140, 140, 137, 134, 133, 131, 99, 100, 101, 101, 102, 102, 103, 104, 104, 105, 106, 107, 107, 108, 107, 107, 107, 107, 106, 107, 111, 115, 118, 118, 121, 121, 122, 121, 118, 114, 113, 114, 116, 118, 122, 125, 129, 132, 135, 135, 135, 135, 136, 137, 140, 144, 147, 149, 149, 150, 150, 149, 148, 146, 144, 142, 141, 138, 138, 137, 134, 132, 130, 128, 99, 99, 100, 100, 101, 102, 103, 105, 106, 106, 107, 108, 108, 108, 108, 107, 107, 107, 107, 108, 112, 117, 119, 119, 121, 122, 122, 121, 118, 115, 113, 114, 115, 117, 120, 124, 128, 132, 135, 136, 136, 136, 137, 139, 141, 145, 147, 149, 148, 148, 148, 147, 145, 144, 141, 139, 137, 135, 134, 133, 130, 128, 126, 125, 98, 99, 99, 99, 100, 101, 103, 104, 107, 107, 108, 109, 109, 108, 107, 107, 107, 107, 107, 108, 112, 118, 121, 121, 121, 122, 122, 121, 118, 115, 114, 114, 114, 115, 118, 123, 127, 132, 135, 137, 137, 137, 138, 141, 143, 146, 148, 149, 148, 147, 146, 145, 144, 142, 140, 137, 135, 132, 131, 130, 126, 124, 123, 121, 97, 97, 98, 98, 99, 101, 103, 104, 106, 107, 108, 109, 109, 109, 108, 107, 107, 107, 107, 107, 111, 117, 121, 122, 122, 122, 122, 121, 119, 116, 114, 114, 115, 115, 118, 122, 127, 131, 135, 137, 138, 138, 140, 142, 145, 147, 149, 149, 147, 146, 145, 143, 142, 141, 138, 136, 133, 130, 129, 128, 125, 122, 121, 118, 96, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 109, 109, 109, 107, 108, 106, 105, 109, 116, 121, 121, 122, 122, 122, 121, 119, 116, 114, 114, 116, 116, 118, 122, 127, 131, 134, 136, 138, 139, 140, 143, 146, 148, 148, 148, 146, 145, 143, 141, 140, 139, 137, 134, 130, 128, 127, 127, 123, 120, 118, 116, 95, 95, 96, 97, 99, 100, 102, 103, 104, 106, 107, 109, 109, 109, 108, 109, 107, 107, 107, 105, 106, 111, 118, 123, 123, 121, 120, 120, 119, 117, 115, 115, 115, 115, 118, 122, 127, 131, 133, 134, 138, 139, 141, 143, 145, 146, 147, 146, 145, 142, 139, 137, 138, 139, 136, 132, 129, 127, 125, 123, 122, 119, 116, 113, 93, 94, 95, 96, 97, 99, 101, 103, 103, 104, 106, 107, 108, 108, 108, 108, 106, 106, 106, 104, 105, 109, 116, 120, 123, 122, 120, 120, 119, 117, 116, 116, 116, 117, 119, 123, 127, 130, 132, 133, 135, 138, 141, 143, 145, 145, 146, 145, 142, 139, 135, 134, 135, 135, 133, 130, 128, 126, 124, 122, 120, 118, 115, 114, 92, 93, 94, 96, 97, 98, 101, 103, 103, 104, 105, 106, 107, 107, 108, 108, 106, 106, 105, 104, 104, 107, 113, 117, 122, 121, 121, 120, 119, 117, 117, 117, 116, 118, 120, 122, 123, 125, 128, 130, 133, 136, 141, 143, 143, 144, 144, 143, 140, 137, 133, 131, 132, 132, 131, 129, 127, 124, 121, 118, 116, 114, 112, 111, 91, 92, 94, 95, 96, 97, 100, 103, 103, 103, 104, 105, 106, 107, 107, 107, 106, 105, 103, 102, 102, 105, 109, 113, 118, 119, 119, 119, 118, 117, 116, 116, 115, 117, 118, 118, 117, 118, 121, 125, 129, 132, 135, 138, 140, 140, 140, 139, 137, 135, 131, 129, 129, 130, 128, 126, 127, 123, 120, 118, 115, 112, 109, 108, 89, 90, 93, 94, 94, 95, 99, 102, 102, 102, 103, 103, 104, 105, 106, 107, 105, 103, 101, 99, 99, 101, 105, 108, 112, 114, 116, 117, 117, 116, 115, 114, 114, 115, 114, 112, 109, 109, 113, 116, 120, 122, 124, 128, 132, 135, 135, 134, 132, 131, 129, 127, 127, 126, 125, 123, 125, 120, 117, 116, 114, 109, 103, 100, 88, 90, 92, 93, 93, 94, 97, 101, 101, 101, 101, 101, 103, 104, 105, 106, 104, 101, 98, 97, 97, 98, 100, 103, 107, 110, 113, 115, 115, 115, 113, 111, 112, 111, 109, 105, 101, 101, 103, 106, 109, 110, 112, 116, 122, 127, 129, 128, 127, 127, 126, 125, 124, 123, 122, 120, 121, 117, 113, 112, 110, 103, 96, 92, 88, 89, 91, 92, 92, 93, 96, 99, 99, 99, 98, 98, 99, 101, 102, 102, 100, 97, 95, 94, 94, 93, 95, 97, 101, 104, 107, 109, 111, 111, 110, 107, 105, 104, 100, 97, 94, 94, 95, 97, 99, 100, 102, 105, 111, 116, 118, 118, 118, 119, 119, 119, 118, 117, 117, 116, 115, 111, 108, 105, 100, 91, 84, 81, 86, 87, 89, 90, 91, 92, 94, 97, 98, 96, 95, 95, 95, 96, 97, 97, 95, 92, 91, 91, 91, 89, 89, 91, 95, 98, 101, 103, 105, 106, 105, 103, 98, 96, 93, 91, 90, 90, 90, 91, 93, 94, 95, 98, 102, 106, 108, 108, 109, 110, 111, 111, 110, 110, 110, 109, 104, 100, 96, 91, 84, 73, 67, 65, 85, 86, 88, 89, 89, 91, 93, 94, 94, 93, 92, 92, 92, 92, 92, 92, 90, 88, 86, 86, 86, 85, 85, 85, 89, 90, 94, 96, 98, 101, 100, 96, 93, 90, 87, 86, 86, 87, 88, 89, 89, 91, 92, 92, 94, 97, 99, 99, 99, 100, 101, 100, 100, 101, 100, 98, 90, 84, 79, 74, 67, 60, 57, 55, 82, 83, 84, 86, 87, 89, 90, 90, 88, 87, 86, 86, 86, 86, 86, 87, 85, 83, 83, 82, 82, 81, 81, 81, 81, 83, 86, 88, 90, 94, 95, 92, 89, 86, 84, 84, 84, 85, 86, 86, 87, 87, 88, 89, 91, 93, 93, 93, 92, 92, 91, 89, 89, 89, 87, 84, 75, 69, 65, 62, 57, 53, 52, 52, 78, 78, 80, 82, 83, 85, 85, 85, 81, 80, 78, 77, 77, 76, 77, 79, 78, 78, 78, 78, 78, 76, 76, 76, 76, 77, 80, 82, 85, 89, 91, 88, 84, 82, 81, 81, 82, 82, 83, 83, 84, 83, 83, 84, 84, 84, 83, 83, 83, 81, 79, 78, 78, 78, 74, 71, 67, 64, 62, 61, 58, 57, 58, 58, 65, 66, 67, 69, 69, 70, 70, 70, 69, 69, 68, 67, 67, 67, 69, 70, 73, 73, 74, 74, 74, 73, 73, 74, 75, 76, 79, 81, 83, 88, 90, 88, 83, 81, 80, 80, 80, 80, 80, 81, 81, 79, 78, 78, 76, 74, 74, 75, 76, 75, 73, 73, 74, 74, 72, 70, 68, 66, 67, 68, 66, 65, 66, 65, 52, 54, 55, 55, 53, 52, 53, 54, 53, 54, 55, 56, 57, 59, 60, 62, 64, 65, 67, 68, 68, 68, 70, 72, 72, 74, 77, 79, 81, 86, 88, 86, 83, 81, 78, 77, 76, 75, 75, 76, 76, 75, 74, 73, 70, 68, 70, 73, 75, 75, 75, 76, 76, 76, 76, 75, 73, 72, 73, 74, 73, 73, 74, 73, 49, 50, 50, 49, 46, 44, 45, 47, 45, 46, 47, 49, 51, 52, 53, 54, 56, 56, 58, 59, 60, 61, 64, 67, 68, 70, 74, 76, 78, 82, 85, 83, 80, 77, 74, 72, 70, 70, 70, 71, 71, 71, 71, 70, 69, 70, 73, 77, 81, 81, 81, 82, 81, 80, 80, 82, 81, 79, 80, 81, 81, 83, 84, 83, 51, 51, 50, 48, 45, 43, 44, 46, 47, 47, 48, 50, 52, 52, 53, 54, 54, 54, 55, 56, 57, 58, 61, 63, 64, 66, 70, 72, 74, 78, 80, 78, 75, 73, 71, 70, 70, 70, 72, 74, 74, 75, 76, 76, 77, 80, 83, 84, 88, 88, 88, 88, 87, 86, 86, 88, 87, 86, 87, 89, 90, 92, 92, 90, 58, 57, 54, 51, 49, 48, 49, 50, 51, 51, 52, 55, 57, 58, 59, 60, 59, 58, 59, 59, 60, 60, 61, 63, 63, 64, 68, 69, 70, 74, 76, 74, 73, 72, 72, 72, 74, 76, 78, 81, 81, 83, 85, 86, 88, 91, 92, 92, 93, 92, 92, 93, 92, 91, 91, 93, 92, 93, 95, 98, 99, 100, 97, 93, 61, 61, 59, 56, 53, 52, 52, 54, 54, 56, 58, 60, 62, 64, 67, 69, 67, 68, 67, 67, 70, 70, 67, 66, 68, 69, 69, 69, 69, 70, 73, 74, 74, 75, 77, 80, 82, 84, 87, 90, 92, 93, 94, 96, 97, 97, 97, 96, 96, 96, 96, 95, 94, 94, 96, 97, 99, 100, 102, 104, 105, 104, 102, 101, 66, 65, 63, 60, 57, 56, 56, 57, 59, 61, 63, 65, 66, 69, 71, 73, 75, 77, 77, 77, 79, 79, 78, 78, 76, 76, 75, 73, 72, 74, 77, 80, 82, 83, 85, 87, 89, 91, 93, 96, 98, 98, 99, 100, 100, 100, 100, 99, 99, 99, 99, 99, 98, 99, 100, 102, 103, 105, 106, 108, 109, 109, 107, 106, 70, 69, 67, 64, 62, 61, 60, 60, 63, 65, 67, 69, 70, 73, 75, 77, 78, 81, 81, 81, 82, 83, 82, 84, 83, 83, 82, 80, 78, 79, 83, 86, 89, 90, 91, 93, 95, 96, 98, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 104, 104, 105, 107, 108, 109, 110, 112, 113, 114, 114, 112, 111, 74, 72, 69, 68, 66, 66, 64, 64, 65, 66, 68, 70, 72, 74, 77, 79, 82, 84, 84, 83, 85, 86, 86, 87, 86, 87, 87, 86, 85, 86, 88, 90, 93, 93, 95, 96, 97, 98, 100, 102, 103, 104, 104, 104, 104, 104, 105, 106, 106, 108, 109, 110, 111, 112, 114, 116, 114, 115, 117, 118, 119, 119, 117, 116, 76, 74, 72, 70, 70, 69, 69, 68, 67, 69, 70, 72, 73, 75, 77, 79, 84, 86, 85, 86, 89, 90, 90, 90, 91, 90, 89, 89, 90, 91, 92, 93, 95, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 108, 109, 110, 110, 112, 114, 116, 117, 118, 119, 121, 122, 120, 121, 122, 123, 123, 123, 121, 120, 77, 75, 73, 72, 71, 71, 71, 72, 72, 73, 74, 74, 74, 75, 77, 79, 83, 84, 84, 86, 90, 92, 91, 91, 95, 93, 91, 90, 92, 93, 94, 95, 97, 97, 99, 101, 101, 102, 104, 106, 107, 109, 111, 112, 113, 113, 114, 114, 118, 120, 122, 124, 125, 125, 126, 126, 125, 125, 126, 127, 127, 126, 124, 123, 78, 78, 76, 74, 72, 72, 74, 75, 77, 77, 77, 77, 77, 77, 79, 80, 84, 86, 87, 89, 92, 94, 94, 95, 97, 95, 94, 93, 94, 95, 96, 96, 99, 100, 101, 103, 104, 106, 108, 110, 111, 113, 115, 117, 117, 118, 119, 120, 124, 126, 129, 131, 131, 131, 130, 130, 130, 130, 130, 130, 130, 129, 127, 126, 81, 80, 79, 76, 74, 74, 76, 79, 80, 81, 81, 80, 80, 80, 81, 83, 84, 88, 89, 90, 93, 94, 95, 96, 97, 97, 97, 98, 98, 98, 98, 97, 101, 102, 104, 106, 107, 108, 110, 113, 115, 117, 120, 122, 123, 124, 125, 127, 130, 132, 135, 137, 137, 135, 135, 134, 134, 134, 134, 134, 133, 132, 130, 129]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFxLdu-U9NDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "6429e6f0-8dd0-47e6-c44f-f25e2cf8b4a9"
      },
      "source": [
        "import pandas as pd\n",
        "temp=1\n",
        "temp1=0\n",
        "df = pd.DataFrame(data={\"pixel\": fat,  \"label\":  temp })\n",
        "df1 = pd.DataFrame(data={\"pixel\": non_fat,  \"label\":  temp1 })\n",
        "frames = [df, df1]\n",
        "result = pd.concat(frames)\n",
        "print(df)\n",
        "print(df1)\n",
        "print(result)\n",
        "\n",
        "result.to_csv(\"./file1.csv\", sep=',',index=False)\n",
        "# print(df[0][0])"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  pixel  label\n",
            "0     [102, 100, 98, 97, 97, 96, 96, 96, 96, 95, 94,...      1\n",
            "1     [151, 150, 147, 145, 144, 144, 143, 142, 142, ...      1\n",
            "2     [162, 166, 170, 172, 174, 173, 174, 178, 180, ...      1\n",
            "3     [132, 134, 136, 137, 139, 141, 142, 143, 145, ...      1\n",
            "4     [79, 77, 76, 76, 77, 77, 78, 79, 81, 80, 80, 8...      1\n",
            "...                                                 ...    ...\n",
            "1675  [103, 101, 98, 95, 92, 90, 88, 87, 87, 87, 87,...      1\n",
            "1676  [165, 165, 166, 165, 165, 164, 164, 165, 164, ...      1\n",
            "1677  [126, 129, 132, 134, 136, 137, 137, 135, 133, ...      1\n",
            "1678  [123, 122, 122, 123, 123, 123, 122, 121, 120, ...      1\n",
            "1679  [225, 227, 228, 229, 230, 231, 232, 233, 233, ...      1\n",
            "\n",
            "[1680 rows x 2 columns]\n",
            "                                                  pixel  label\n",
            "0     [90, 90, 91, 91, 89, 87, 86, 87, 88, 88, 90, 9...      0\n",
            "1     [34, 38, 42, 46, 48, 51, 55, 57, 60, 62, 64, 6...      0\n",
            "2     [100, 100, 100, 100, 99, 98, 99, 101, 105, 108...      0\n",
            "3     [43, 40, 38, 39, 40, 41, 50, 63, 74, 81, 89, 9...      0\n",
            "4     [128, 131, 130, 128, 129, 131, 135, 140, 142, ...      0\n",
            "...                                                 ...    ...\n",
            "3355  [146, 148, 149, 148, 146, 145, 142, 140, 139, ...      0\n",
            "3356  [109, 108, 106, 104, 103, 102, 101, 101, 98, 9...      0\n",
            "3357  [200, 198, 194, 189, 185, 180, 176, 172, 171, ...      0\n",
            "3358  [91, 93, 93, 92, 94, 95, 90, 85, 86, 82, 81, 8...      0\n",
            "3359  [161, 163, 164, 163, 162, 160, 158, 155, 153, ...      0\n",
            "\n",
            "[3360 rows x 2 columns]\n",
            "                                                  pixel  label\n",
            "0     [102, 100, 98, 97, 97, 96, 96, 96, 96, 95, 94,...      1\n",
            "1     [151, 150, 147, 145, 144, 144, 143, 142, 142, ...      1\n",
            "2     [162, 166, 170, 172, 174, 173, 174, 178, 180, ...      1\n",
            "3     [132, 134, 136, 137, 139, 141, 142, 143, 145, ...      1\n",
            "4     [79, 77, 76, 76, 77, 77, 78, 79, 81, 80, 80, 8...      1\n",
            "...                                                 ...    ...\n",
            "3355  [146, 148, 149, 148, 146, 145, 142, 140, 139, ...      0\n",
            "3356  [109, 108, 106, 104, 103, 102, 101, 101, 98, 9...      0\n",
            "3357  [200, 198, 194, 189, 185, 180, 176, 172, 171, ...      0\n",
            "3358  [91, 93, 93, 92, 94, 95, 90, 85, 86, 82, 81, 8...      0\n",
            "3359  [161, 163, 164, 163, 162, 160, 158, 155, 153, ...      0\n",
            "\n",
            "[5040 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhN7TUYTNGM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "698934ce-714c-4b3c-c8f5-67283b8d89e2"
      },
      "source": [
        "print(len(fat_right_eye[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYLjhfOaYi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmL1e_scEZyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790LYslaSxZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbQBNi4DSzY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4a650d83-094f-4945-eb10-4a3a815efc52"
      },
      "source": [
        "df = pd.read_csv('/content/file1.csv')\n",
        "print(df.shape)\n",
        "df.head()\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5040, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[102, 100, 98, 97, 97, 96, 96, 96, 96, 95, 94,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[151, 150, 147, 145, 144, 144, 143, 142, 142, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[162, 166, 170, 172, 174, 173, 174, 178, 180, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[132, 134, 136, 137, 139, 141, 142, 143, 145, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[79, 77, 76, 76, 77, 77, 78, 79, 81, 80, 80, 8...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               pixel  label\n",
              "0  [102, 100, 98, 97, 97, 96, 96, 96, 96, 95, 94,...      1\n",
              "1  [151, 150, 147, 145, 144, 144, 143, 142, 142, ...      1\n",
              "2  [162, 166, 170, 172, 174, 173, 174, 178, 180, ...      1\n",
              "3  [132, 134, 136, 137, 139, 141, 142, 143, 145, ...      1\n",
              "4  [79, 77, 76, 76, 77, 77, 78, 79, 81, 80, 80, 8...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e-gqVaVTkU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b99d18a4-74f0-472d-8125-06184e04c104"
      },
      "source": [
        "var = str(str(df['Right_Eye'][0])[1:-1]).replace(',','')\n",
        "print(var)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102 100 98 97 97 96 96 96 96 95 94 95 96 97 96 95 96 96 96 96 97 99 102 105 107 108 109 111 114 117 120 122 126 127 129 130 130 131 132 133 136 135 135 134 134 133 134 135 135 136 138 140 140 140 140 141 140 141 140 141 143 143 144 148 103 101 99 98 97 96 96 96 94 93 92 92 94 95 94 94 95 95 95 96 96 97 99 102 105 107 109 110 113 117 121 122 126 127 129 130 131 132 133 135 135 135 135 135 134 134 134 135 135 136 138 140 141 140 141 141 141 141 141 141 143 143 144 148 105 104 102 100 99 97 96 96 94 92 90 90 91 93 93 92 92 93 94 95 95 96 98 99 105 106 109 111 114 118 121 123 125 127 129 130 131 132 133 135 135 135 135 135 135 135 135 136 136 137 138 140 141 141 142 142 141 142 142 142 143 143 144 147 108 106 104 103 101 99 98 97 94 92 89 88 89 90 90 89 90 91 92 94 95 95 97 99 103 105 108 110 113 117 121 123 126 127 128 129 130 131 132 134 134 134 135 136 136 136 136 137 137 138 139 141 142 142 143 144 141 143 142 142 143 143 144 147 109 108 106 105 103 100 98 97 93 90 87 85 86 87 87 87 88 88 90 91 92 93 95 97 100 102 106 108 112 116 121 123 126 127 129 130 130 131 133 134 134 135 136 137 137 137 138 139 139 139 140 142 142 142 143 144 143 144 144 143 143 143 143 146 110 109 107 106 103 100 97 95 91 88 85 83 84 85 86 85 87 87 88 89 90 91 93 95 97 100 104 108 111 116 121 123 126 127 129 130 131 132 134 135 135 136 138 139 140 140 141 142 140 140 141 142 142 142 143 144 144 146 145 143 143 143 143 144 113 111 109 107 104 100 96 94 90 87 84 82 83 83 84 84 85 85 86 88 88 89 91 93 96 99 103 106 110 114 119 121 124 125 126 128 129 130 132 133 135 136 138 140 141 141 142 143 141 141 141 141 142 142 143 144 143 145 145 143 143 143 143 144 115 113 111 109 105 100 96 94 89 86 83 81 81 81 81 81 81 82 84 86 87 87 89 92 95 98 101 104 107 111 115 117 121 123 124 125 126 127 129 130 132 133 135 138 139 139 140 141 141 141 141 141 141 141 142 143 142 144 144 143 143 144 144 145 117 113 111 109 105 101 97 93 89 87 83 80 82 83 81 80 79 79 81 84 85 85 86 89 94 96 100 103 106 108 112 114 115 117 119 120 121 125 128 130 130 131 132 133 134 136 139 141 141 141 141 141 141 140 140 140 142 141 141 142 142 143 144 147 118 114 112 110 106 102 98 94 89 87 84 82 83 82 79 77 76 77 78 80 81 83 86 88 90 91 94 98 102 105 108 109 110 112 113 115 117 120 123 123 125 126 128 129 131 134 137 139 138 138 138 137 137 138 138 139 139 138 138 140 142 143 145 147 121 116 114 111 106 102 98 94 91 88 86 85 84 81 77 74 74 76 77 78 79 81 84 85 88 89 90 93 97 100 102 103 104 105 106 108 110 113 114 114 116 118 120 123 126 129 131 132 135 134 134 134 134 135 136 136 135 134 135 138 141 143 145 148 123 118 115 111 106 102 99 95 93 90 88 87 84 81 78 75 74 76 77 76 78 80 80 78 82 83 85 88 90 93 95 96 98 99 101 102 103 104 105 105 107 108 112 115 118 120 120 120 124 125 126 127 128 128 129 130 130 129 131 134 138 142 146 149 125 120 116 112 107 103 99 96 94 91 90 88 85 84 81 77 72 72 71 71 73 75 74 72 73 75 78 81 82 84 87 89 91 94 96 96 96 96 97 98 99 100 102 105 107 110 111 112 113 114 116 118 119 119 119 119 122 122 124 129 135 140 146 150 130 124 118 113 108 104 101 97 95 92 92 90 86 87 84 75 66 64 61 61 63 66 67 66 67 70 73 75 75 76 78 80 84 87 90 90 89 89 91 92 93 93 93 94 96 100 103 106 108 109 111 112 111 110 109 109 112 114 119 126 134 140 147 152 135 128 121 116 111 107 103 99 97 94 94 91 88 89 81 66 56 53 50 50 52 54 56 57 61 64 67 68 68 68 69 70 76 78 81 81 80 81 82 83 83 83 83 83 85 87 91 93 96 97 99 99 99 99 99 100 107 111 118 128 136 143 151 156 139 131 124 118 112 108 104 100 99 96 95 93 90 90 78 58 46 44 42 43 44 44 45 47 52 55 58 61 62 63 64 64 69 70 72 72 72 73 73 73 73 74 75 75 75 76 78 79 76 78 80 82 85 88 91 94 107 111 120 131 139 146 154 159 144 135 125 118 113 109 106 103 100 98 95 94 93 90 77 63 54 55 53 49 43 38 39 41 46 45 46 49 52 54 55 56 57 58 59 61 61 61 61 61 61 60 59 60 61 59 59 62 63 68 72 74 77 80 88 95 111 121 131 138 145 152 158 163 146 137 128 121 115 111 108 104 101 98 96 95 95 95 86 75 68 67 65 61 55 50 48 47 47 45 43 42 43 43 43 44 45 45 45 46 47 47 47 47 47 47 47 46 47 46 47 51 63 74 85 92 97 101 107 115 128 136 144 149 154 158 162 166 150 141 132 125 118 114 110 107 105 101 98 96 96 97 93 85 80 78 76 72 69 65 62 60 60 56 51 47 45 44 44 44 46 44 43 42 42 42 42 42 44 47 48 48 49 51 54 59 70 84 101 112 118 123 130 137 144 151 156 159 163 165 167 169 152 144 136 129 122 117 113 109 109 104 100 98 98 99 97 93 89 87 84 81 79 78 76 75 74 70 64 57 53 52 54 55 56 53 50 49 49 50 50 50 54 60 63 63 65 68 72 78 83 98 113 123 130 137 145 153 154 159 163 166 169 171 171 172 153 147 140 133 126 120 116 112 110 106 103 102 101 103 103 101 98 97 93 90 87 86 85 83 82 80 75 67 62 62 64 67 66 63 61 59 61 63 65 66 68 74 78 78 79 80 84 89 98 110 121 130 138 147 155 162 163 168 171 172 176 177 177 177 155 150 144 139 131 125 121 117 112 108 106 105 104 104 104 103 101 101 99 95 93 92 90 87 89 88 85 78 72 72 74 76 75 73 70 69 70 72 74 75 77 83 86 88 89 90 94 99 111 121 131 139 148 157 164 169 172 176 177 178 180 180 179 179 157 153 149 144 137 131 126 122 118 113 111 109 107 105 105 105 105 105 103 100 99 99 97 94 94 95 92 87 84 84 85 85 86 84 81 78 78 79 80 81 84 88 92 96 100 103 109 116 126 136 145 152 160 167 172 175 177 180 181 180 182 182 181 181 159 155 152 148 141 135 130 126 123 118 115 114 111 110 110 111 113 112 108 105 105 107 106 103 101 102 100 97 95 96 96 95 97 95 93 90 89 90 91 93 96 99 102 107 113 118 125 134 140 150 158 163 169 174 176 178 179 182 182 182 184 185 184 184 160 156 154 151 145 140 134 128 127 123 119 116 114 114 115 115 115 114 112 112 111 110 111 112 112 110 107 105 105 105 105 106 107 106 104 103 103 103 104 107 109 113 118 123 129 137 144 149 156 160 166 171 174 177 178 178 179 181 183 184 185 185 185 184 162 159 156 154 149 145 140 135 131 128 123 119 118 117 118 118 118 117 116 116 115 115 115 116 116 115 113 112 111 112 113 113 113 113 112 111 113 114 116 120 126 129 133 137 143 150 156 160 163 167 172 175 177 178 179 179 181 183 185 185 186 186 186 185 165 161 159 157 153 149 145 141 137 133 128 124 121 121 120 120 121 120 119 119 119 118 119 119 120 119 118 117 117 117 118 119 119 120 120 121 123 125 129 133 140 142 146 150 155 161 165 167 171 174 177 178 179 180 181 182 183 184 185 186 186 187 187 186 166 162 160 158 155 153 150 146 143 139 134 129 127 125 124 123 123 122 121 121 121 121 121 122 122 122 121 120 120 120 121 122 124 126 126 127 130 132 136 141 147 150 153 156 160 165 168 169 174 176 179 179 179 180 182 183 183 185 186 186 186 186 187 187 166 163 162 161 158 157 155 152 149 146 141 137 134 131 129 128 126 125 124 124 123 123 124 125 126 126 125 125 125 125 126 127 129 131 132 133 136 139 142 147 154 157 160 162 165 168 170 172 175 177 179 179 179 180 182 184 184 185 186 186 186 186 187 187 166 164 163 163 161 161 160 158 153 151 146 142 139 136 133 131 131 129 127 127 126 126 127 128 129 129 129 128 129 130 131 132 134 135 137 139 142 145 148 153 159 162 164 166 167 169 171 172 176 178 180 180 180 181 183 184 184 185 186 186 186 187 187 187 166 164 165 165 164 164 164 162 158 155 151 147 144 141 138 136 136 134 131 130 129 129 130 131 132 131 130 130 131 133 134 135 137 139 140 143 147 150 153 157 162 164 165 167 169 171 172 172 176 178 180 180 180 181 182 183 183 185 186 186 187 187 187 187 168 166 167 167 166 166 166 164 164 161 157 152 149 146 144 142 140 137 135 133 132 131 133 134 134 133 132 132 133 134 136 136 139 141 142 145 150 152 155 158 164 165 166 168 171 174 174 174 175 177 179 180 180 181 182 182 182 184 186 186 186 187 186 186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mDa6-FdVMiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a12730ce-8693-4c09-8955-39f89ebaab88"
      },
      "source": [
        "df['pixel'] = df.pixel.apply(lambda x: str(x)[1:-1].replace(',',''))\n",
        "# df['Left_Eye'] = df.Left_Eye.apply(lambda x: str(x)[1:-1].replace(',',''))\n",
        "# df['Mouth'] = df.Mouth.apply(lambda x: str(x)[1:-1].replace(',',''))\n",
        "#img_array = np.stack(img_array, axis=0)\n",
        "print(df.shape)\n",
        "# print(len(df.Mouth[2].split(' ')))\n",
        "df.head()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5040, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102 100 98 97 97 96 96 96 96 95 94 95 96 97 96...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>151 150 147 145 144 144 143 142 142 140 140 14...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162 166 170 172 174 173 174 178 180 180 183 18...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>132 134 136 137 139 141 142 143 145 148 147 15...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79 77 76 76 77 77 78 79 81 80 80 81 82 82 83 8...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               pixel  label\n",
              "0  102 100 98 97 97 96 96 96 96 95 94 95 96 97 96...      1\n",
              "1  151 150 147 145 144 144 143 142 142 140 140 14...      1\n",
              "2  162 166 170 172 174 173 174 178 180 180 183 18...      1\n",
              "3  132 134 136 137 139 141 142 143 145 148 147 15...      1\n",
              "4  79 77 76 76 77 77 78 79 81 80 80 81 82 82 83 8...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e42jAgYQg30v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b521dc59-8fa3-4988-de9b-cdcf76ccd665"
      },
      "source": [
        "img_arr = df.pixel.apply(lambda x : np.array(str(x).split(' ')).reshape(64,32,1).astype('float32'))\n",
        "img_arr_f = np.stack(img_arr,axis=0)\n",
        "print(img_arr_f.shape)\n",
        "# img=[]\n",
        "# img_arr1 = df.Right_Eye.apply(lambda x : np.array(str(x).split(' ')).reshape(64,32,1).astype('float32'))\n",
        "# print(img_arr1.shape)\n",
        "# img_arr2 = df.Left_Eye.apply(lambda x : np.array(str(x).split(' ')).reshape(64,32,1).astype('float32'))\n",
        "# img_arr3 = df.Mouth.apply(lambda x : np.array(str(x).split(' ')[0:2048]).reshape(64,32,1).astype('float32'))\n",
        "# # img.append(img_arr1)\n",
        "# # img.append(img_arr2)\n",
        "# # img.append(img_arr3)\n",
        "# print(df.head())\n",
        "# img_arr_f = np.concatenate((img_arr1,img_arr2,img_arr3))\n",
        "# print(img_arr_f.shape)\n",
        "# img_array1 = np.stack(img_arr1, axis=0)\n",
        "# img_array2 = np.stack(img_arr2, axis=0)\n",
        "# img_array3 = np.stack(img_arr3, axis=0)\n",
        "# img_arr = np.stack(img_arr_f,axis=0)\n",
        "# print(img_arr.shape)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5040, 64, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geZSeYpc12aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a43e9291-cb62-41fe-f84e-890607230373"
      },
      "source": [
        "le = LabelEncoder()\n",
        "img_labels = le.fit_transform(df.label)\n",
        "img_labels = np_utils.to_categorical(img_labels)\n",
        "img_labels.shape"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5040, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnk0Z6kDozxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "024f8f23-6c4d-47c1-82a3-727c03e9a080"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(img_arr_f, img_labels,\n",
        "                                                    shuffle=True,stratify=img_labels,\n",
        "                                                    test_size=0.1, random_state=42)\n",
        "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4536, 64, 32, 1), (504, 64, 32, 1), (4536, 2), (504, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39__gb2N710o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "img_depth = X_train.shape[3]\n",
        "num_classes = y_train.shape[1]"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FAH1EBM8zeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing results, as neural networks are very sensitive to unnormalized data.\n",
        "X_train = X_train / 255.\n",
        "X_valid = X_valid / 255."
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff3upqrd9FtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_net(optim):\n",
        "    \"\"\"\n",
        "    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\n",
        "    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\n",
        "    atleast in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\n",
        "    results.\n",
        "    \"\"\"\n",
        "    net = Sequential(name='DCNN')\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5,5),\n",
        "            input_shape=(img_width, img_height, img_depth),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5,5),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_2'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
        "    net.add(Dropout(0.4, name='dropout_1'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_3'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_4'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
        "    net.add(Dropout(0.4, name='dropout_2'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_5'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_6'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
        "    net.add(Dropout(0.5, name='dropout_3'))\n",
        "\n",
        "    net.add(Flatten(name='flatten'))\n",
        "        \n",
        "    net.add(\n",
        "        Dense(\n",
        "            128,\n",
        "            activation='elu',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='dense_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\n",
        "    \n",
        "    net.add(Dropout(0.6, name='dropout_4'))\n",
        "    \n",
        "    net.add(\n",
        "        Dense(\n",
        "            num_classes,\n",
        "            activation='softmax',\n",
        "            name='out_layer'\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    net.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optim,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    net.summary()\n",
        "    \n",
        "    return net"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhA76MXz9HbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "I used two callbacks one is `early stopping` for avoiding overfitting training data\n",
        "and other `ReduceLROnPlateau` for learning rate.\n",
        "\"\"\"\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=11,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0BNkZmI9P74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As the data in hand is less as compared to the task so ImageDataGenerator is good to go.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "train_datagen.fit(X_train)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wi59V3O9VdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccadc462-c1e8-47c3-e67a-54b36f3bf16c"
      },
      "source": [
        "batch_size = 32 #batch size of 32 performs the best.\n",
        "epochs = 100\n",
        "optims = [\n",
        "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
        "    optimizers.Adam(0.001),\n",
        "]\n",
        "\n",
        "# I tried both `Nadam` and `Adam`, the difference in results is not different but I finally went with Nadam as it is more popular.\n",
        "model = build_net(optims[1]) \n",
        "history = model.fit_generator(\n",
        "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    steps_per_epoch=len(X_train) / batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    use_multiprocessing=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"DCNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 32, 64)        1664      \n",
            "_________________________________________________________________\n",
            "batchnorm_1 (BatchNormalizat (None, 64, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 32, 64)        102464    \n",
            "_________________________________________________________________\n",
            "batchnorm_2 (BatchNormalizat (None, 64, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "maxpool2d_1 (MaxPooling2D)   (None, 32, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batchnorm_3 (BatchNormalizat (None, 32, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batchnorm_4 (BatchNormalizat (None, 32, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "maxpool2d_2 (MaxPooling2D)   (None, 16, 8, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 8, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 8, 256)        295168    \n",
            "_________________________________________________________________\n",
            "batchnorm_5 (BatchNormalizat (None, 16, 8, 256)        1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 8, 256)        590080    \n",
            "_________________________________________________________________\n",
            "batchnorm_6 (BatchNormalizat (None, 16, 8, 256)        1024      \n",
            "_________________________________________________________________\n",
            "maxpool2d_3 (MaxPooling2D)   (None, 8, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "batchnorm_7 (BatchNormalizat (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 2,263,874\n",
            "Trainable params: 2,261,826\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-187-22665cd605d0>:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "141/141 [============================>.] - ETA: 1s - loss: 0.9777 - accuracy: 0.5881WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "142/141 [==============================] - 319s 2s/step - loss: 0.9761 - accuracy: 0.5888 - val_loss: 0.7031 - val_accuracy: 0.6071 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "141/141 [============================>.] - ETA: 1s - loss: 0.7083 - accuracy: 0.6641WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "142/141 [==============================] - 317s 2s/step - loss: 0.7085 - accuracy: 0.6640 - val_loss: 0.5311 - val_accuracy: 0.7083 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "130/141 [==========================>...] - ETA: 25s - loss: 0.6391 - accuracy: 0.6787"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yK17rhW_CJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_yaml = model.to_yaml()\n",
        "with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "    \n",
        "model.save(\"model_f.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}